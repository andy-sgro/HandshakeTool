
Handshake Tool UI:
	- mockup
	- welcome screen
		- new/open button
	- read xmls to create boxes
	- unify UI so viewport is in the middle at all times
	- add crosshairs with inverted colours
Handshake Engine Algorithm:
	- protect input

- connect handshake tool to trained model to automation
	- send image data through sockets
	
- train
	- create label map
	- partition images
	- generate-tfrecord.py
	- create /model/ and copy pipeline.config to it, and edit it
		- 3, number of classes
		- 131, gigabytes of memory, be less if GPU-based
	- train.py
	
- export
	- export.py


commands:
	- python generate_tfrecord.py -x [PATH_TO_IMAGES_FOLDER]/train -l [PATH_TO_ANNOTATIONS_FOLDER]/label_map.pbtxt -o [PATH_TO_ANNOTATIONS_FOLDER]/train.record
	- python generate_tfrecord.py -x [PATH_TO_IMAGES_FOLDER]/test -l [PATH_TO_ANNOTATIONS_FOLDER]/label_map.pbtxt -o [PATH_TO_ANNOTATIONS_FOLDER]/test.record
	- python model_main_tf2.py --model_dir=models/my_ssd_resnet50_v1_fpn --pipeline_config_path=models/my_ssd_resnet50_v1_fpn/pipeline.config
	- python .\exporter_main_v2.py --input_type image_tensor --pipeline_config_path .\models\my_efficientdet_d1\pipeline.config --trained_checkpoint_dir .\models\my_efficientdet_d1\ --output_directory .\exported-models\my_model


Exported folder:
	/annotations/
	/exported-model/
	real-time-detection.py

/my-project/
	/annotations/
	/exported-model/
	/images/
		/train/
		/test/
	/model/
	
/machine-learning/
	/pre-trained-model/
	export.py
	train.py (model_main_tf2.py)
	generate-tfrecord.py
	real-time-detection.py

Project Schema:
	Label
		int id
		string label

	Box
		string filename
		int imageFolder
		int label
		int xmin
		int xmax
		int ymin
		int ymax